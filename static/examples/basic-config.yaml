# Example Gateway Configuration

This is a basic example configuration for the Radicalbit AI Gateway.

## Basic Configuration

```yaml
routes:
  customer-service:
    chat_models:
      - model_id: gpt-3.5-turbo
        model: openai/gpt-3.5-turbo
        credentials:
          api_key: "YOUR_OPENAI_API_KEY"
        params:
          temperature: 0.7
          max_tokens: 1000
        system_prompt: "You are a helpful customer service assistant."

guardrails:
  - name: profanity_filter
    type: contains
    where: input
    behavior: block
    parameters:
      values: ["inappropriate", "offensive"]
    response_message: "Content blocked due to inappropriate language"
```

## Multi-Model Configuration

```yaml
routes:
  business-assistant:
    chat_models:
      - model_id: gpt-4o-mini
        model: openai/gpt-4o-mini
        credentials:
          api_key: "YOUR_OPENAI_API_KEY"
        params:
          temperature: 0.3
          max_tokens: 2000
      - model_id: claude-3-haiku
        model: anthropic/claude-3-haiku-20240307
        credentials:
          api_key: "YOUR_ANTHROPIC_API_KEY"
        params:
          temperature: 0.3
          max_tokens: 2000
    
    balancing:
      algorithm: weighted_round_robin
      weights:
        - model_id: gpt-4o-mini
          weight: 2
        - model_id: claude-3-haiku
          weight: 1
    
    fallback:
      - target: gpt-4o-mini
        fallbacks:
          - claude-3-haiku
      - target: claude-3-haiku
        fallbacks:
          - gpt-4o-mini

guardrails:
  - name: business_context_judge
    type: judge
    where: input
    behavior: block
    parameters:
      judge_config:
        prompt_ref: "business_context_check.md"
        model_id: "gpt-3.5-turbo"
        temperature: 0.7
        max_tokens: 150
        threshold: 0.001
    response_message: "Request not aligned with business context"
```

## Advanced Configuration with Guardrails

```yaml
routes:
  secure-chat:
    chat_models:
      - model_id: gpt-4o-mini
        model: openai/gpt-4o-mini
        credentials:
          api_key: "YOUR_OPENAI_API_KEY"
        params:
          temperature: 0.7
          max_tokens: 1500
    
    guardrails:
      - toxicity_judge
      - pii_anonymizer
      - business_context_judge
    
    rate_limiting:
      algorithm: fixed_window
      window_size: 60 seconds
      max_requests: 100

guardrails:
  - name: toxicity_judge
    type: judge
    where: input
    behavior: soft_block
    parameters:
      judge_config:
        prompt_ref: "toxicity_check.md"
        model_id: "gpt-3.5-turbo"
        temperature: 0.0
        max_tokens: 100
        threshold: 0.01
    response_message: "ðŸš¨ BLOCKED - Toxic content detected"

  - name: pii_anonymizer
    type: presidio_anonymizer
    where: io
    behavior: warn
    parameters:
      language: en
      entities: ["EMAIL_ADDRESS", "PHONE_NUMBER", "CREDIT_CARD"]

  - name: business_context_judge
    type: judge
    where: input
    behavior: block
    parameters:
      judge_config:
        prompt_ref: "business_context_check.md"
        model_id: "gpt-3.5-turbo"
        temperature: 0.7
        max_tokens: 150
        threshold: 0.001
    response_message: "Request not aligned with business context"
```

## Environment Variables

Create a `.env` file for sensitive configuration:

```bash
OPENAI_API_KEY=sk-your-openai-key
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
```

Then reference them in your configuration:

```yaml
credentials:
  api_key: !secret OPENAI_API_KEY
```
