# Example Gateway Configuration
# --------------------------------
# This is a basic example configuration for the Radicalbit AI Gateway
# using the NEW structure:
# - chat_models / embedding_models are top-level
# - routes reference model IDs (strings)

```yaml
# -------------------------
# Models (top-level)
# -------------------------
chat_models:
  - model_id: gpt-3.5-turbo
    model: openai/gpt-3.5-turbo
    credentials:
      api_key: !secret OPENAI_API_KEY
    params:
      temperature: 0.7
      max_tokens: 1000
    prompt: "You are a helpful customer service assistant."
    role: system

  - model_id: gpt-4o-mini
    model: openai/gpt-4o-mini
    credentials:
      api_key: !secret OPENAI_API_KEY
    params:
      temperature: 0.3
      max_tokens: 2000

  - model_id: claude-3-haiku
    model: anthropic/claude-3-haiku-20240307
    credentials:
      api_key: !secret ANTHROPIC_API_KEY
    params:
      temperature: 0.3
      max_tokens: 2000

# -------------------------
# Routes
# -------------------------
routes:
  # Basic Configuration
  customer-service:
    chat_models:
      - gpt-3.5-turbo

  # Multi-Model Configuration (with fallback)
  business-assistant:
    chat_models:
      - gpt-4o-mini
      - claude-3-haiku
    fallback:
      - target: gpt-4o-mini
        fallbacks:
          - claude-3-haiku
      - target: claude-3-haiku
        fallbacks:
          - gpt-4o-mini
    guardrails:
      - business_context_judge

  # Advanced Configuration with Guardrails + Rate Limiting
  secure-chat:
    chat_models:
      - gpt-4o-mini
    guardrails:
      - toxicity_judge
      - pii_anonymizer
      - business_context_judge
    rate_limiting:
      algorithm: fixed_window
      window_size: 60 seconds
      max_requests: 100

# -------------------------
# Guardrails (top-level)
# -------------------------
guardrails:
  - name: profanity_filter
    type: contains
    where: input
    behavior: block
    parameters:
      values: ["inappropriate", "offensive"]
    response_message: "Content blocked due to inappropriate language"

  - name: toxicity_judge
    type: judge
    where: input
    behavior: soft_block
    response_message: "ðŸš¨ BLOCKED - Toxic content detected"
    parameters:
      prompt_ref: "toxicity_check.md"
      model_id: gpt-3.5-turbo
      temperature: 0.0
      max_tokens: 100

  - name: pii_anonymizer
    type: presidio_anonymizer
    where: io
    behavior: warn
    parameters:
      language: en
      entities: ["EMAIL_ADDRESS", "PHONE_NUMBER", "CREDIT_CARD"]

  - name: business_context_judge
    type: judge
    where: input
    behavior: block
    response_message: "Request not aligned with business context"
    parameters:
      prompt_ref: "business_context_check.md"
      model_id: gpt-3.5-turbo
      temperature: 0.7
      max_tokens: 150
```